{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_lorenz import get_lorenz_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training, validation, testing data\n",
    "noise_strength = 1e-6\n",
    "training_data = get_lorenz_data(1024, noise_strength=noise_strength)\n",
    "validation_data = get_lorenz_data(20, noise_strength=noise_strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = 128\n",
    "params['latent_dim'] = 3\n",
    "params['model_order'] = 1\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = False\n",
    "params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_z'] = 0.0\n",
    "params['loss_weight_sindy_x'] = 1e-4\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [64,32]\n",
    "\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "params['batch_size'] = 1024\n",
    "params['learning_rate'] = 1e-3\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 100\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5001\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['library_dim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "TRAINING\n",
      "Epoch 0\n",
      "   training loss 0.05453329533338547, (0.052450776, 755.5524, 20.739746, 0.85454184)\n",
      "   validation loss 0.032162345945835114, (0.031135589, 602.38855, 10.182131, 0.85454184)\n",
      "decoder loss ratio: 0.166338, decoder SINDy loss  ratio: 1.002543\n",
      "Epoch 100\n",
      "   training loss 6.121747719589621e-05, (2.8406937e-05, 0.5605071, 0.13725197, 1.9085344)\n",
      "   validation loss 4.176954098511487e-05, (1.3914819e-05, 0.28489405, 0.087693766, 1.9085344)\n",
      "decoder loss ratio: 0.000074, decoder SINDy loss  ratio: 0.008634\n",
      "Epoch 200\n",
      "   training loss 3.51043781847693e-05, (1.574617e-05, 0.09636041, 0.02697572, 1.6660637)\n",
      "   validation loss 2.7724579922505654e-05, (9.0503145e-06, 0.07483972, 0.020136282, 1.6660637)\n",
      "decoder loss ratio: 0.000048, decoder SINDy loss  ratio: 0.001983\n",
      "Epoch 300\n",
      "   training loss 4.467913822736591e-05, (2.8730368e-05, 0.112844415, 0.020276966, 1.3921074)\n",
      "   validation loss 3.3178686862811446e-05, (1.7746512e-05, 0.058128975, 0.015110997, 1.3921074)\n",
      "decoder loss ratio: 0.000095, decoder SINDy loss  ratio: 0.001488\n",
      "Epoch 400\n",
      "   training loss 2.08700803341344e-05, (6.614763e-06, 0.13678561, 0.01700522, 1.2554796)\n",
      "   validation loss 1.7288313756580465e-05, (3.8122078e-06, 0.05716171, 0.0092130955, 1.2554796)\n",
      "decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000907\n",
      "Epoch 500\n",
      "   training loss 1.666833668423351e-05, (3.521393e-06, 0.18608451, 0.012569227, 1.1890022)\n",
      "   validation loss 1.5540119420620613e-05, (2.8301706e-06, 0.0783183, 0.008199273, 1.1890022)\n",
      "decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000807\n",
      "THRESHOLDING: 24 active coefficients\n",
      "Epoch 600\n",
      "   training loss 1.806471118470654e-05, (5.290746e-06, 0.13791452, 0.013467327, 1.1427232)\n",
      "   validation loss 1.7738904716679826e-05, (5.342715e-06, 0.092155755, 0.009689584, 1.1427232)\n",
      "decoder loss ratio: 0.000029, decoder SINDy loss  ratio: 0.000954\n",
      "Epoch 700\n",
      "   training loss 2.530260280764196e-05, (1.2459567e-05, 0.14705183, 0.017060857, 1.113695)\n",
      "   validation loss 2.4966851924546063e-05, (1.2967561e-05, 0.09228294, 0.008623403, 1.113695)\n",
      "decoder loss ratio: 0.000069, decoder SINDy loss  ratio: 0.000849\n",
      "Epoch 800\n",
      "   training loss 1.6697129467502236e-05, (4.5288552e-06, 0.19069183, 0.012533266, 1.0914949)\n",
      "   validation loss 1.5751549653941765e-05, (4.2557926e-06, 0.0918089, 0.005808093, 1.0914949)\n",
      "decoder loss ratio: 0.000023, decoder SINDy loss  ratio: 0.000572\n",
      "Epoch 900\n",
      "   training loss 1.5754661944811232e-05, (3.930255e-06, 0.19127463, 0.010708708, 1.0753536)\n",
      "   validation loss 1.4424483197217342e-05, (3.0955339e-06, 0.10893493, 0.0057541314, 1.0753536)\n",
      "decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000567\n",
      "Epoch 1000\n",
      "   training loss 1.801536200218834e-05, (6.5994436e-06, 0.17955644, 0.007925101, 1.0623409)\n",
      "   validation loss 1.8371943951933645e-05, (6.875202e-06, 0.12274159, 0.008733341, 1.0623409)\n",
      "decoder loss ratio: 0.000037, decoder SINDy loss  ratio: 0.000860\n",
      "THRESHOLDING: 15 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 1.943830466188956e-05, (7.222958e-06, 0.29188076, 0.01594601, 1.0620745)\n",
      "   validation loss 1.8142007320420817e-05, (6.93572e-06, 0.10752417, 0.005855412, 1.0620745)\n",
      "decoder loss ratio: 0.000037, decoder SINDy loss  ratio: 0.000577\n",
      "Epoch 1200\n",
      "   training loss 1.557888936076779e-05, (3.5749945e-06, 0.2423772, 0.014766487, 1.0527247)\n",
      "   validation loss 1.4904879208188504e-05, (3.7350349e-06, 0.11434267, 0.0064259744, 1.0527247)\n",
      "decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000633\n",
      "Epoch 1300\n",
      "   training loss 1.5026394976302981e-05, (3.2347707e-06, 0.23643272, 0.01339456, 1.0452168)\n",
      "   validation loss 1.3574672266258858e-05, (2.6924902e-06, 0.121534, 0.0043001394, 1.0452168)\n",
      "decoder loss ratio: 0.000014, decoder SINDy loss  ratio: 0.000423\n",
      "Epoch 1400\n",
      "   training loss 1.3737302651861683e-05, (2.4132714e-06, 0.20458895, 0.009337104, 1.0390321)\n",
      "   validation loss 1.376758336846251e-05, (2.8895802e-06, 0.11468321, 0.004876824, 1.0390321)\n",
      "decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000480\n",
      "Epoch 1500\n",
      "   training loss 1.4615428881370462e-05, (3.3440413e-06, 0.18074287, 0.009330926, 1.0338296)\n",
      "   validation loss 1.3462587958201766e-05, (2.6636533e-06, 0.1283031, 0.0046063894, 1.0338296)\n",
      "decoder loss ratio: 0.000014, decoder SINDy loss  ratio: 0.000454\n",
      "THRESHOLDING: 15 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 1.5135171452129725e-05, (3.8266785e-06, 0.22587447, 0.01017897, 1.0290596)\n",
      "   validation loss 1.4661389286629856e-05, (3.8975477e-06, 0.15472366, 0.004732462, 1.0290596)\n",
      "decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.000466\n",
      "Epoch 1700\n",
      "   training loss 1.6685899026924744e-05, (5.6081412e-06, 0.20409377, 0.008325653, 1.0245193)\n",
      "   validation loss 1.722101296763867e-05, (6.235875e-06, 0.16033684, 0.0073994407, 1.0245193)\n",
      "decoder loss ratio: 0.000033, decoder SINDy loss  ratio: 0.000729\n",
      "Epoch 1800\n",
      "   training loss 3.078709778492339e-05, (1.865039e-05, 0.28692168, 0.019306112, 1.0206096)\n",
      "   validation loss 2.5807483325479552e-05, (1.4421402e-05, 0.20223959, 0.0117998645, 1.0206096)\n",
      "decoder loss ratio: 0.000077, decoder SINDy loss  ratio: 0.001162\n",
      "Epoch 1900\n",
      "   training loss 2.0141253116889857e-05, (9.247558e-06, 0.21952218, 0.0072238874, 1.0171306)\n",
      "   validation loss 2.410236993455328e-05, (1.2921667e-05, 0.19416215, 0.010093959, 1.0171306)\n",
      "decoder loss ratio: 0.000069, decoder SINDy loss  ratio: 0.000994\n",
      "Epoch 2000\n",
      "   training loss 2.0131075871177018e-05, (8.994605e-06, 0.26073605, 0.009966471, 1.0139824)\n",
      "   validation loss 1.8573209672467783e-05, (7.810325e-06, 0.2030094, 0.006230617, 1.0139824)\n",
      "decoder loss ratio: 0.000042, decoder SINDy loss  ratio: 0.000613\n",
      "THRESHOLDING: 15 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 2.151460648747161e-05, (1.0767395e-05, 0.20855105, 0.006422572, 1.0104954)\n",
      "   validation loss 2.405095801805146e-05, (1.3096685e-05, 0.21714072, 0.0084932055, 1.0104954)\n",
      "decoder loss ratio: 0.000070, decoder SINDy loss  ratio: 0.000836\n",
      "Epoch 2200\n",
      "   training loss 1.562250872666482e-05, (4.895022e-06, 0.21459842, 0.0065033855, 1.0077149)\n",
      "   validation loss 1.369351775792893e-05, (3.1949603e-06, 0.1806267, 0.0042140894, 1.0077149)\n",
      "decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000415\n",
      "Epoch 2300\n",
      "   training loss 1.3540970940084662e-05, (2.9018404e-06, 0.21943776, 0.0059453757, 1.0044594)\n",
      "   validation loss 1.3201409274188336e-05, (2.7513463e-06, 0.21350254, 0.004054698, 1.0044594)\n",
      "decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000399\n",
      "Epoch 2400\n",
      "   training loss 1.3777835192740895e-05, (2.8855288e-06, 0.17340946, 0.008801939, 1.0012113)\n",
      "   validation loss 1.2684497960435692e-05, (2.2447687e-06, 0.19195485, 0.0042761685, 1.0012113)\n",
      "decoder loss ratio: 0.000012, decoder SINDy loss  ratio: 0.000421\n",
      "Epoch 2500\n",
      "   training loss 1.4615502550441306e-05, (3.5917783e-06, 0.18649466, 0.010400688, 0.9983655)\n",
      "   validation loss 1.374127168674022e-05, (3.3087672e-06, 0.1972437, 0.0044884966, 0.9983655)\n",
      "decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000442\n",
      "THRESHOLDING: 15 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 1.7171729268739e-05, (6.29035e-06, 0.20719504, 0.00924055, 0.9957325)\n",
      "   validation loss 1.744553810567595e-05, (7.0098e-06, 0.21458966, 0.0047841338, 0.9957325)\n",
      "decoder loss ratio: 0.000037, decoder SINDy loss  ratio: 0.000471\n",
      "Epoch 2700\n",
      "   training loss 1.2385399713821243e-05, (1.9059885e-06, 0.23479827, 0.0054894043, 0.99304706)\n",
      "   validation loss 1.1744730727514252e-05, (1.4485246e-06, 0.18586722, 0.0036573554, 0.99304706)\n",
      "decoder loss ratio: 0.000008, decoder SINDy loss  ratio: 0.000360\n",
      "Epoch 2800\n",
      "   training loss 1.2785457329300698e-05, (2.2957054e-06, 0.246639, 0.005839668, 0.99057853)\n",
      "   validation loss 1.2336975487414747e-05, (2.0791492e-06, 0.20843527, 0.0035204075, 0.99057853)\n",
      "decoder loss ratio: 0.000011, decoder SINDy loss  ratio: 0.000347\n",
      "Epoch 2900\n",
      "   training loss 1.3874210708308965e-05, (3.001449e-06, 0.28772876, 0.009897052, 0.9883057)\n",
      "   validation loss 1.3745573596679606e-05, (3.4488958e-06, 0.21355431, 0.0041362112, 0.9883057)\n",
      "decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000407\n",
      "Epoch 3000\n",
      "   training loss 1.2979863640794065e-05, (2.1203741e-06, 0.31467345, 0.010007577, 0.98587316)\n",
      "   validation loss 1.2261342817510013e-05, (1.9429638e-06, 0.24079935, 0.004596477, 0.98587316)\n",
      "decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000453\n",
      "THRESHOLDING: 15 active coefficients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3100\n",
      "   training loss 1.288807652599644e-05, (2.1631804e-06, 0.34031788, 0.008919002, 0.9832996)\n",
      "   validation loss 1.1956529306189623e-05, (1.7763231e-06, 0.2535894, 0.0034721077, 0.9832996)\n",
      "decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000342\n",
      "Epoch 3200\n",
      "   training loss 1.6838759620441124e-05, (6.3061843e-06, 0.4150729, 0.007180103, 0.9814565)\n",
      "   validation loss 1.6289024642901495e-05, (5.8863407e-06, 0.2846285, 0.005881198, 0.9814565)\n",
      "decoder loss ratio: 0.000031, decoder SINDy loss  ratio: 0.000579\n",
      "Epoch 3300\n",
      "   training loss 1.417461044184165e-05, (3.3637039e-06, 0.37145472, 0.010192955, 0.9791611)\n",
      "   validation loss 1.37914321385324e-05, (3.5299502e-06, 0.3354979, 0.0046987124, 0.9791611)\n",
      "decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000463\n",
      "Epoch 3400\n",
      "   training loss 1.3897266398998909e-05, (3.5244295e-06, 0.32160842, 0.00597421, 0.9775416)\n",
      "   validation loss 1.4667040886706673e-05, (4.2946385e-06, 0.33874625, 0.0059698587, 0.9775416)\n",
      "decoder loss ratio: 0.000023, decoder SINDy loss  ratio: 0.000588\n",
      "Epoch 3500\n",
      "   training loss 1.4050872778170742e-05, (3.6894548e-06, 0.35133696, 0.0060493127, 0.97564876)\n",
      "   validation loss 1.3381832104641944e-05, (3.117196e-06, 0.36733413, 0.005081496, 0.97564876)\n",
      "decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000500\n",
      "THRESHOLDING: 15 active coefficients\n",
      "Epoch 3600\n",
      "   training loss 1.5684036043239757e-05, (5.1408188e-06, 0.3698605, 0.0080357855, 0.973964)\n",
      "   validation loss 1.4200975783751346e-05, (3.8639637e-06, 0.38068953, 0.0059737205, 0.973964)\n",
      "decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.000588\n",
      "Epoch 3700\n",
      "   training loss 1.4553301298292354e-05, (4.23671e-06, 0.35630202, 0.0059159356, 0.9724998)\n",
      "   validation loss 1.577247167006135e-05, (5.3859353e-06, 0.36956438, 0.0066153947, 0.9724998)\n",
      "decoder loss ratio: 0.000029, decoder SINDy loss  ratio: 0.000651\n",
      "Epoch 3800\n",
      "   training loss 1.5406301827169955e-05, (5.101396e-06, 0.3655664, 0.0059505897, 0.97098464)\n",
      "   validation loss 1.7520433175377548e-05, (7.05573e-06, 0.38986748, 0.0075485716, 0.97098464)\n",
      "decoder loss ratio: 0.000038, decoder SINDy loss  ratio: 0.000743\n",
      "Epoch 3900\n",
      "   training loss 1.2255661204108037e-05, (1.9951185e-06, 0.28901687, 0.00565035, 0.9695507)\n",
      "   validation loss 1.2119504390284419e-05, (2.0010284e-06, 0.37784266, 0.004229684, 0.9695507)\n",
      "decoder loss ratio: 0.000011, decoder SINDy loss  ratio: 0.000416\n",
      "Epoch 4000\n",
      "   training loss 1.34373658511322e-05, (3.1501927e-06, 0.3085036, 0.0060336487, 0.96838087)\n",
      "   validation loss 1.3598359146271832e-05, (3.329455e-06, 0.35182044, 0.0058509554, 0.96838087)\n",
      "decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000576\n",
      "THRESHOLDING: 15 active coefficients\n",
      "Epoch 4100\n",
      "   training loss 2.0451185264391825e-05, (9.580221e-06, 0.25644562, 0.012014066, 0.9669559)\n",
      "   validation loss 1.8609951439430006e-05, (7.995458e-06, 0.3340517, 0.009449353, 0.9669559)\n",
      "decoder loss ratio: 0.000043, decoder SINDy loss  ratio: 0.000930\n",
      "Epoch 4200\n",
      "   training loss 1.1937596354982816e-05, (1.6710896e-06, 0.21280693, 0.0060726767, 0.9659239)\n",
      "   validation loss 1.1307974091323558e-05, (1.2308791e-06, 0.32278034, 0.0041785627, 0.9659239)\n",
      "decoder loss ratio: 0.000007, decoder SINDy loss  ratio: 0.000411\n",
      "Epoch 4300\n",
      "   training loss 1.1932825145777315e-05, (1.7103325e-06, 0.24320059, 0.0057761334, 0.96448797)\n",
      "   validation loss 1.1548659131221939e-05, (1.4934053e-06, 0.32585248, 0.0041037463, 0.96448797)\n",
      "decoder loss ratio: 0.000008, decoder SINDy loss  ratio: 0.000404\n",
      "Epoch 4400\n",
      "   training loss 1.3444887372315861e-05, (2.8134339e-06, 0.25359604, 0.010047877, 0.9626666)\n",
      "   validation loss 1.3010005204705521e-05, (2.8510785e-06, 0.3240299, 0.0053226054, 0.9626666)\n",
      "decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000524\n",
      "Epoch 4500\n",
      "   training loss 2.6043362595373765e-05, (1.5522579e-05, 0.3319846, 0.009082576, 0.96125257)\n",
      "   validation loss 2.4145683710230514e-05, (1.387518e-05, 0.30895737, 0.0065797865, 0.96125257)\n",
      "decoder loss ratio: 0.000074, decoder SINDy loss  ratio: 0.000648\n",
      "THRESHOLDING: 13 active coefficients\n",
      "Epoch 4600\n",
      "   training loss 1.3399294402915984e-05, (3.2301164e-06, 0.3055202, 0.0052906307, 0.9640115)\n",
      "   validation loss 1.374104613205418e-05, (3.5469334e-06, 0.3388422, 0.005539983, 0.9640115)\n",
      "decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000545\n",
      "Epoch 4700\n",
      "   training loss 1.348969635728281e-05, (3.279492e-06, 0.27445522, 0.0059560407, 0.96146005)\n",
      "   validation loss 1.304440593230538e-05, (2.9010014e-06, 0.34516895, 0.005288041, 0.96146005)\n",
      "decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000521\n",
      "Epoch 4800\n",
      "   training loss 1.2458054698072374e-05, (2.1764067e-06, 0.25376797, 0.0068276767, 0.9598881)\n",
      "   validation loss 1.1942644050577655e-05, (1.8568895e-06, 0.28872743, 0.0048687328, 0.9598881)\n",
      "decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000479\n",
      "Epoch 4900\n",
      "   training loss 1.2720315680780914e-05, (2.6226357e-06, 0.2674359, 0.0051509524, 0.9582585)\n",
      "   validation loss 1.3917568139731884e-05, (3.7700706e-06, 0.30622634, 0.005649135, 0.9582585)\n",
      "decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000556\n",
      "Epoch 5000\n",
      "   training loss 1.5082508070918266e-05, (4.4734397e-06, 0.35518208, 0.0103892945, 0.9570139)\n",
      "   validation loss 1.3931544344814029e-05, (3.863806e-06, 0.3268513, 0.004975997, 0.9570139)\n",
      "decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.000490\n",
      "THRESHOLDING: 13 active coefficients\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 2.224372337877867e-06, (1.6974903e-06, 0.24911745, 0.0052688196, 0.96270365)\n",
      "   validation loss 2.1901983018324245e-06, (1.7248146e-06, 0.29784834, 0.004653838, 0.96270365)\n",
      "decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000458\n",
      "Epoch 100\n",
      "   training loss 2.6991892809746787e-06, (2.3372288e-06, 0.27709195, 0.0036196057, 1.0000608)\n",
      "   validation loss 2.7880164452653844e-06, (2.5073803e-06, 0.2416932, 0.0028063622, 1.0000608)\n",
      "decoder loss ratio: 0.000013, decoder SINDy loss  ratio: 0.000276\n",
      "Epoch 200\n",
      "   training loss 2.128708047166583e-06, (1.7870228e-06, 0.29285547, 0.0034168516, 1.0052783)\n",
      "   validation loss 1.846695454332803e-06, (1.5833218e-06, 0.2525516, 0.0026337365, 1.0052783)\n",
      "decoder loss ratio: 0.000008, decoder SINDy loss  ratio: 0.000259\n",
      "Epoch 300\n",
      "   training loss 3.960260983149055e-06, (3.5297608e-06, 0.25365776, 0.004305, 1.0083708)\n",
      "   validation loss 5.54733151147957e-06, (5.2230043e-06, 0.23067106, 0.003243272, 1.0083708)\n",
      "decoder loss ratio: 0.000028, decoder SINDy loss  ratio: 0.000319\n",
      "Epoch 400\n",
      "   training loss 1.0645334441505838e-05, (9.848271e-06, 0.31731546, 0.007970637, 1.0104703)\n",
      "   validation loss 1.4055856809136458e-05, (1.35193795e-05, 0.28351915, 0.0053647743, 1.0104703)\n",
      "decoder loss ratio: 0.000072, decoder SINDy loss  ratio: 0.000528\n",
      "Epoch 500\n",
      "   training loss 5.158653493708698e-06, (4.5716333e-06, 0.278218, 0.005870201, 1.0121204)\n",
      "   validation loss 5.2297541515144985e-06, (4.8963716e-06, 0.34477594, 0.0033338238, 1.0121204)\n",
      "decoder loss ratio: 0.000026, decoder SINDy loss  ratio: 0.000328\n",
      "Epoch 600\n",
      "   training loss 4.566285952023463e-06, (4.07276e-06, 0.32262468, 0.004935259, 1.0138471)\n",
      "   validation loss 6.027181825629668e-06, (5.5608143e-06, 0.34326324, 0.0046636756, 1.0138471)\n",
      "decoder loss ratio: 0.000030, decoder SINDy loss  ratio: 0.000459\n",
      "Epoch 700\n",
      "   training loss 5.3289818424673285e-06, (4.9209584e-06, 0.28601393, 0.0040802364, 1.0153632)\n",
      "   validation loss 6.171177119540516e-06, (5.8032556e-06, 0.28724268, 0.0036792138, 1.0153632)\n",
      "decoder loss ratio: 0.000031, decoder SINDy loss  ratio: 0.000362\n",
      "Epoch 800\n",
      "   training loss 3.5993141409562668e-06, (3.2965465e-06, 0.28743342, 0.0030276752, 1.0165263)\n",
      "   validation loss 3.7512843391596107e-06, (3.536236e-06, 0.37684232, 0.0021504841, 1.0165263)\n",
      "decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000212\n",
      "Epoch 900\n",
      "   training loss 7.974059371917974e-06, (7.440075e-06, 0.3282617, 0.0053398465, 1.0177273)\n",
      "   validation loss 8.907410119718406e-06, (8.584089e-06, 0.34951767, 0.0032332086, 1.0177273)\n",
      "decoder loss ratio: 0.000046, decoder SINDy loss  ratio: 0.000318\n",
      "Epoch 1000\n",
      "   training loss 8.312776117236353e-06, (7.66818e-06, 0.367273, 0.00644596, 1.0187614)\n",
      "   validation loss 8.961093953985255e-06, (8.438597e-06, 0.37423855, 0.005224964, 1.0187614)\n",
      "decoder loss ratio: 0.000045, decoder SINDy loss  ratio: 0.000514\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12764\\871650853.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mresults_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'experiment_results_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y%m%d%H%M\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5991\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "num_experiments = 1\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'lorenz_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    data_to_append = {**results_dict, **params}\n",
    "    df_the_dict = pd.DataFrame({'name':data_to_append.keys(), 'value':data_to_append.values()})\n",
    "    df = pd.concat([df, df_the_dict], ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame()\n",
    "data_to_append = {**results_dict, **params}\n",
    "df_the_dict = pd.DataFrame({'name':data_to_append.keys(), 'value':data_to_append.values()})\n",
    "df = pd.concat([df, df_the_dict], ignore_index=True)\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_epochs</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x_norm</td>\n",
       "      <td>0.187182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sindy_predict_norm_x</td>\n",
       "      <td>10.156299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sindy_predict_norm_z</td>\n",
       "      <td>119.689163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sindy_coefficients</td>\n",
       "      <td>[[5.7870493, 6.579703, -0.00012655504], [0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>loss_decoder</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loss_decoder_sindy</td>\n",
       "      <td>0.005225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loss_sindy</td>\n",
       "      <td>0.374239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>loss_sindy_regularization</td>\n",
       "      <td>1.018761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>validation_losses</td>\n",
       "      <td>[[0.032162346, 0.031135589, 602.38855, 10.1821...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sindy_model_terms</td>\n",
       "      <td>[60.0, 24.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>input_dim</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>latent_dim</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model_order</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>poly_order</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>include_sine</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>library_dim</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sequential_thresholding</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>coefficient_threshold</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>threshold_frequency</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>coefficient_mask</td>\n",
       "      <td>[[True, True, False], [False, True, True], [Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>coefficient_initialization</td>\n",
       "      <td>constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>loss_weight_decoder</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loss_weight_sindy_z</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>loss_weight_sindy_x</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>loss_weight_sindy_regularization</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>activation</td>\n",
       "      <td>sigmoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>widths</td>\n",
       "      <td>[64, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>epoch_size</td>\n",
       "      <td>256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>batch_size</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data_path</td>\n",
       "      <td>C:\\Users\\milos\\OneDrive\\IX_semestar_master\\mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>print_progress</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>print_frequency</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>max_epochs</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>refinement_epochs</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>save_name</td>\n",
       "      <td>lorenz_2024_01_16_00_35_15_279636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name  \\\n",
       "0                         num_epochs   \n",
       "1                             x_norm   \n",
       "2               sindy_predict_norm_x   \n",
       "3               sindy_predict_norm_z   \n",
       "4                 sindy_coefficients   \n",
       "5                       loss_decoder   \n",
       "6                 loss_decoder_sindy   \n",
       "7                         loss_sindy   \n",
       "8          loss_sindy_regularization   \n",
       "9                  validation_losses   \n",
       "10                 sindy_model_terms   \n",
       "11                         input_dim   \n",
       "12                        latent_dim   \n",
       "13                       model_order   \n",
       "14                        poly_order   \n",
       "15                      include_sine   \n",
       "16                       library_dim   \n",
       "17           sequential_thresholding   \n",
       "18             coefficient_threshold   \n",
       "19               threshold_frequency   \n",
       "20                  coefficient_mask   \n",
       "21        coefficient_initialization   \n",
       "22               loss_weight_decoder   \n",
       "23               loss_weight_sindy_z   \n",
       "24               loss_weight_sindy_x   \n",
       "25  loss_weight_sindy_regularization   \n",
       "26                        activation   \n",
       "27                            widths   \n",
       "28                        epoch_size   \n",
       "29                        batch_size   \n",
       "30                     learning_rate   \n",
       "31                         data_path   \n",
       "32                    print_progress   \n",
       "33                   print_frequency   \n",
       "34                        max_epochs   \n",
       "35                 refinement_epochs   \n",
       "36                         save_name   \n",
       "\n",
       "                                                value  \n",
       "0                                                5000  \n",
       "1                                            0.187182  \n",
       "2                                           10.156299  \n",
       "3                                          119.689163  \n",
       "4   [[5.7870493, 6.579703, -0.00012655504], [0.000...  \n",
       "5                                            0.000008  \n",
       "6                                            0.005225  \n",
       "7                                            0.374239  \n",
       "8                                            1.018761  \n",
       "9   [[0.032162346, 0.031135589, 602.38855, 10.1821...  \n",
       "10  [60.0, 24.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15....  \n",
       "11                                                128  \n",
       "12                                                  3  \n",
       "13                                                  1  \n",
       "14                                                  3  \n",
       "15                                              False  \n",
       "16                                                 20  \n",
       "17                                               True  \n",
       "18                                                0.1  \n",
       "19                                                500  \n",
       "20  [[True, True, False], [False, True, True], [Fa...  \n",
       "21                                           constant  \n",
       "22                                                1.0  \n",
       "23                                                0.0  \n",
       "24                                             0.0001  \n",
       "25                                            0.00001  \n",
       "26                                            sigmoid  \n",
       "27                                           [64, 32]  \n",
       "28                                             256000  \n",
       "29                                               1024  \n",
       "30                                              0.001  \n",
       "31  C:\\Users\\milos\\OneDrive\\IX_semestar_master\\mas...  \n",
       "32                                               True  \n",
       "33                                                100  \n",
       "34                                               5001  \n",
       "35                                               1001  \n",
       "36                  lorenz_2024_01_16_00_35_15_279636  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
